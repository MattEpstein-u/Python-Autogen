{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcde1e6",
   "metadata": {},
   "source": [
    "# Multi-Agent Framework (Gemini + AutoGen)\n",
    "\n",
    "This notebook serves as a standalone framework for running multi-agent systems using Google's Gemini models. It allows for flexible orchestration (Parallel or Round Robin) and easy modification of agents.\n",
    "\n",
    "**Structure:**\n",
    "1.  **Setup**: Environment and API Key configuration.\n",
    "2.  **Model**: Initialization of the Gemini model client.\n",
    "3.  **Agents**: Definition of specialized agents (Planner, Local, Language, Summary).\n",
    "4.  **Orchestration**: Functions to run the agents in different patterns.\n",
    "5.  **Execution**: Define the task and run the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f6bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (crucial for running asyncio in notebooks)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- API Key Setup ---\n",
    "# 1. Try environment variable\n",
    "# 2. Try looking for 'list_models.py' in the current directory (legacy support)\n",
    "# 3. Fail if not found\n",
    "\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    try:\n",
    "        if os.path.exists(\"list_models.py\"):\n",
    "            with open(\"list_models.py\", \"r\") as f:\n",
    "                txt = f.read()\n",
    "            m = re.search(r\"api_key\\s*=\\s*[\\\"']([^\\\"']+)[\\\"']\", txt)\n",
    "            if m:\n",
    "                os.environ[\"GOOGLE_API_KEY\"] = m.group(1)\n",
    "                print(\"Loaded GOOGLE_API_KEY from list_models.py\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read list_models.py: {e}\")\n",
    "\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"ERROR: GOOGLE_API_KEY not set. Please set it in the environment variables or provide it here.\")\n",
    "    # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\" # Uncomment and set if needed\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY is set.\")\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelFamily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defc3840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: models/gemini-2.5-flash\n",
      "Model client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Configuration ---\n",
    "\n",
    "model_name = \"models/gemini-2.5-flash\"\n",
    "\n",
    "# Minimal model_info for AutoGen to identify Gemini capabilities\n",
    "model_info = {\n",
    "    \"vision\": False,\n",
    "    \"function_calling\": True,\n",
    "    \"json_output\": True,\n",
    "    \"family\": ModelFamily.GEMINI_2_5_FLASH,\n",
    "    \"structured_output\": True,\n",
    "    \"multiple_system_messages\": True,\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(f\"Initializing model: {model_name}\")\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model_name,\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "        model_info=model_info,\n",
    "    )\n",
    "    print(\"Model client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create model client: {e}\")\n",
    "    model_client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e6a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- Agent Definitions ---\n",
    "\n",
    "if model_client:\n",
    "    planner_agent = AssistantAgent(\n",
    "        \"planner_agent\",\n",
    "        model_client=model_client,\n",
    "        description=\"A helpful assistant that can plan trips.\",\n",
    "        system_message=\"You are a helpful assistant that can suggest a travel plan for a user based on their request.\",\n",
    "    )\n",
    "\n",
    "    local_agent = AssistantAgent(\n",
    "        \"local_agent\",\n",
    "        model_client=model_client,\n",
    "        description=\"A local assistant that can suggest local activities or places to visit.\",\n",
    "        system_message=\"You are a helpful assistant that can suggest authentic and interesting local activities or places to visit for a user and can utilize any context information provided.\",\n",
    "    )\n",
    "\n",
    "    language_agent = AssistantAgent(\n",
    "        \"language_agent\",\n",
    "        model_client=model_client,\n",
    "        description=\"A helpful assistant that can provide language tips for a given destination.\",\n",
    "        system_message=(\n",
    "            \"You are a helpful assistant that can review travel plans, providing feedback on important/critical tips \"\n",
    "            \"about how best to address language or communication challenges for the given destination.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Base Summary Agent (Used for Parallel Mode where it just synthesizes provided text)\n",
    "    travel_summary_agent_parallel = AssistantAgent(\n",
    "        \"travel_summary_agent\",\n",
    "        model_client=model_client,\n",
    "        description=\"A helpful assistant that can summarize the travel plan.\",\n",
    "        system_message=(\n",
    "            \"You are a helpful assistant that can take in all of the suggestions and advice from the other agents and provide a detailed final travel plan. \"\n",
    "            \"You must ensure that the final plan is integrated and complete. YOUR FINAL RESPONSE MUST BE THE COMPLETE PLAN.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Interactive Summary Agent (Used for Round Robin / Dynamic Modes where it participates and terminates)\n",
    "    travel_summary_agent_interactive = AssistantAgent(\n",
    "        \"travel_summary_agent\",\n",
    "        model_client=model_client,\n",
    "        description=\"A helpful assistant that can summarize the travel plan.\",\n",
    "        system_message=(\n",
    "            \"You are a helpful assistant that can take in all of the suggestions and advice from the other agents and provide a detailed final travel plan. \"\n",
    "            \"You must ensure that the final plan is integrated and complete. YOUR FINAL RESPONSE MUST BE THE COMPLETE PLAN. \"\n",
    "            \"When the plan is complete and all perspectives are integrated, you can respond with TERMINATE.\"\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    print(\"Agents initialized.\")\n",
    "else:\n",
    "    print(\"Model client invalid, skipping agent initialization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02de4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Orchestration Logic ---\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "async def process_stream(stream, filename: str):\n",
    "    \"\"\"\n",
    "    Consumes the agent stream, prints to console, and writes to a file.\n",
    "    \"\"\"\n",
    "    print(f\"--- Output will be saved to {filename} ---\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        async for message in stream:\n",
    "            # Basic formatting for the log/console\n",
    "            output = \"\"\n",
    "            if isinstance(message, TextMessage):\n",
    "                output = f\"\\n[{message.source}]: {message.content}\\n\"\n",
    "            else:\n",
    "                output = f\"\\n[{message.source}]: {str(message)}\\n\"\n",
    "            \n",
    "            print(output)\n",
    "            f.write(output)\n",
    "\n",
    "\n",
    "async def run_parallel_team(task: str, specialist_agents: list, summary_agent: AssistantAgent, filename=\"output_parallel.txt\"):\n",
    "    \"\"\"\n",
    "    Runs specialist agents in parallel and aggregates their results for a summary agent.\n",
    "    \"\"\"\n",
    "    print(f\"Starting PARALLEL run for task: {task[:50]}...\")\n",
    "    \n",
    "    # 1. Run specialists in parallel\n",
    "    print(\"Dispatching tasks to specialists...\")\n",
    "    results = await asyncio.gather(*[agent.run(task=task) for agent in specialist_agents])\n",
    "    \n",
    "    # 2. Collect responses\n",
    "    collected_context = []\n",
    "    for res in results:\n",
    "        if res.messages:\n",
    "            last_msg = res.messages[-1]\n",
    "            collected_context.append(f\"--- {last_msg.source} suggestions ---\\n{last_msg.content}\")\n",
    "\n",
    "    aggregated_info = \"\\n\\n\".join(collected_context)\n",
    "    print(\"Parallel agents finished. Generating summary...\")\n",
    "\n",
    "    with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"--- PARALLEL AGENT INPUTS ---\\n{aggregated_info}\\n-----------------------------\\n\")\n",
    "\n",
    "    # 3. Final Summary\n",
    "    summary_task = (\n",
    "        f\"Original Request: {task}\\n\\n\"\n",
    "        f\"Below are suggestions from your team:\\n\\n{aggregated_info}\\n\\n\"\n",
    "        \"Please compile these into a cohesive response.\"\n",
    "    )\n",
    "    \n",
    "    await process_stream(summary_agent.run_stream(task=summary_task), filename)\n",
    "\n",
    "\n",
    "async def run_round_robin_team(task: str, participants: list, termination_word=\"TERMINATE\", filename=\"output_round_robin.txt\"):\n",
    "    \"\"\"\n",
    "    Runs agents in a sequential round-robin group chat until termination.\n",
    "    Agents speak in a fixed order: A -> B -> C -> A...\n",
    "    \"\"\"\n",
    "    print(f\"Starting ROUND ROBIN run for task: {task[:50]}...\")\n",
    "    \n",
    "    termination = TextMentionTermination(termination_word)\n",
    "    team = RoundRobinGroupChat(\n",
    "        participants=participants,\n",
    "        termination_condition=termination,\n",
    "    )\n",
    "    \n",
    "    await process_stream(team.run_stream(task=task), filename)\n",
    "\n",
    "\n",
    "async def run_dynamic_router_team(task: str, participants: list, model_client, termination_word=\"TERMINATE\", filename=\"output_dynamic.txt\"):\n",
    "    \"\"\"\n",
    "    Runs agents in a dynamic group chat where the model selects the next speaker.\n",
    "    Best for complex or non-linear tasks.\n",
    "    \"\"\"\n",
    "    print(f\"Starting DYNAMIC ROUTER run for task: {task[:50]}...\")\n",
    "    \n",
    "    termination = TextMentionTermination(termination_word)\n",
    "    \n",
    "    # selector_prompt is optional, but helps guide the router\n",
    "    selector_prompt = (\n",
    "        \"Select the next agent to speak based on the conversation history. \"\n",
    "        \"If the plan is complete and agreed upon, select the summary agent to finalize, or Terminate if done.\"\n",
    "    )\n",
    "\n",
    "    team = SelectorGroupChat(\n",
    "        participants=participants,\n",
    "        model_client=model_client, # The model is needed here to make selection decisions\n",
    "        termination_condition=termination,\n",
    "        selector_prompt=selector_prompt\n",
    "    )\n",
    "    \n",
    "    await process_stream(team.run_stream(task=task), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> MODE 3: DYNAMIC ROUTER execution running...\n",
      "Starting DYNAMIC ROUTER run for task: Plan a 4-day trip to Mexico City. Provide suggesti...\n",
      "--- Output will be saved to output_mode_c_dynamic.txt ---\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - [{'error': {'code': 400, 'message': 'API key expired. Please renew the API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key expired. Please renew the API key.'}]}}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_client:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m>>> MODE 3: DYNAMIC ROUTER execution running...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m run_dynamic_router_team(\n\u001b[32m     10\u001b[39m         task=TASK,\n\u001b[32m     11\u001b[39m         participants=[planner_agent, local_agent, language_agent, travel_summary_agent_interactive],\n\u001b[32m     12\u001b[39m         model_client=model_client,\n\u001b[32m     13\u001b[39m         filename=\u001b[33m\"\u001b[39m\u001b[33moutput_mode_c_dynamic.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     )\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m>>> MODE 3: DONE. Output saved to output_mode_c_dynamic.txt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mrun_dynamic_router_team\u001b[39m\u001b[34m(task, participants, model_client, termination_word, filename)\u001b[39m\n\u001b[32m     81\u001b[39m selector_prompt = (\n\u001b[32m     82\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSelect the next agent to speak based on the conversation history. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIf the plan is complete and agreed upon, select the summary agent to finalize, or Terminate if done.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m )\n\u001b[32m     86\u001b[39m team = SelectorGroupChat(\n\u001b[32m     87\u001b[39m     participants=participants,\n\u001b[32m     88\u001b[39m     model_client=model_client, \u001b[38;5;66;03m# The model is needed here to make selection decisions\u001b[39;00m\n\u001b[32m     89\u001b[39m     termination_condition=termination,\n\u001b[32m     90\u001b[39m     selector_prompt=selector_prompt\n\u001b[32m     91\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m process_stream(team.run_stream(task=task), filename)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mprocess_stream\u001b[39m\u001b[34m(stream, filename)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Output will be saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m# Basic formatting for the log/console\u001b[39;00m\n\u001b[32m     12\u001b[39m         output = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TextMessage):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py:534\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    528\u001b[39m     shutdown_task = asyncio.create_task(stop_runtime())\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    531\u001b[39m     \u001b[38;5;66;03m# Run the team by sending the start message to the group chat manager.\u001b[39;00m\n\u001b[32m    532\u001b[39m     \u001b[38;5;66;03m# The group chat manager will start the group chat by relaying the message to the participants\u001b[39;00m\n\u001b[32m    533\u001b[39m     \u001b[38;5;66;03m# and the group chat manager.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._runtime.send_message(\n\u001b[32m    535\u001b[39m         GroupChatStart(messages=messages, output_task_messages=output_task_messages),\n\u001b[32m    536\u001b[39m         recipient=AgentId(\u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mself\u001b[39m._group_chat_manager_topic_type, key=\u001b[38;5;28mself\u001b[39m._team_id),\n\u001b[32m    537\u001b[39m         cancellation_token=cancellation_token,\n\u001b[32m    538\u001b[39m     )\n\u001b[32m    539\u001b[39m     \u001b[38;5;66;03m# Collect the output messages in order.\u001b[39;00m\n\u001b[32m    540\u001b[39m     output_messages: List[BaseAgentEvent | BaseChatMessage] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_core/_single_threaded_agent_runtime.py:385\u001b[39m, in \u001b[36mSingleThreadedAgentRuntime.send_message\u001b[39m\u001b[34m(self, message, recipient, sender, cancellation_token, message_id)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._message_queue.put(\n\u001b[32m    372\u001b[39m     SendMessageEnvelope(\n\u001b[32m    373\u001b[39m         message=message,\n\u001b[32m   (...)\u001b[39m\u001b[32m    380\u001b[39m     )\n\u001b[32m    381\u001b[39m )\n\u001b[32m    383\u001b[39m cancellation_token.link_future(future)\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_core/_single_threaded_agent_runtime.py:508\u001b[39m, in \u001b[36mSingleThreadedAgentRuntime._process_send\u001b[39m\u001b[34m(self, message_envelope)\u001b[39m\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tracer_helper.trace_block(\n\u001b[32m    497\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprocess\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    498\u001b[39m         recipient_agent.id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m         ),\n\u001b[32m    506\u001b[39m     ):\n\u001b[32m    507\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m MessageHandlerContext.populate_context(recipient_agent.id):\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m             response = \u001b[38;5;28;01mawait\u001b[39;00m recipient_agent.on_message(\n\u001b[32m    509\u001b[39m                 message_envelope.message,\n\u001b[32m    510\u001b[39m                 ctx=message_context,\n\u001b[32m    511\u001b[39m             )\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message_envelope.future.cancelled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_core/_base_agent.py:119\u001b[39m, in \u001b[36mBaseAgent.on_message\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: Any, ctx: MessageContext) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_message_impl(message, ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py:67\u001b[39m, in \u001b[36mSequentialRoutedAgent.on_message_impl\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fifo_lock.acquire()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().on_message_impl(message, ctx)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Release the FIFO lock to allow the next message to be processed.\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m._fifo_lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_core/_routed_agent.py:485\u001b[39m, in \u001b[36mRoutedAgent.on_message_impl\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    484\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m h.router(message, ctx):\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m h(\u001b[38;5;28mself\u001b[39m, message, ctx)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_unhandled_message(message, ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_core/_routed_agent.py:389\u001b[39m, in \u001b[36mrpc.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    387\u001b[39m         logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMessage type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in target types \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m return_value = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, message, ctx)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m AnyType \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m return_types \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(return_value) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m return_types:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat_manager.py:132\u001b[39m, in \u001b[36mBaseGroupChatManager.handle_start\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# Select speakers to start/continue the conversation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transition_to_next_speakers(ctx.cancellation_token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat_manager.py:176\u001b[39m, in \u001b[36mBaseGroupChatManager._transition_to_next_speakers\u001b[39m\u001b[34m(self, cancellation_token)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# Link the select speaker future to the cancellation token.\u001b[39;00m\n\u001b[32m    175\u001b[39m cancellation_token.link_future(speaker_names_future)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m speaker_names = \u001b[38;5;28;01mawait\u001b[39;00m speaker_names_future\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(speaker_names, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# If only one speaker is selected, convert it to a list.\u001b[39;00m\n\u001b[32m    179\u001b[39m     speaker_names = [speaker_names]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_selector_group_chat.py:212\u001b[39m, in \u001b[36mSelectorGroupChatManager.select_speaker\u001b[39m\u001b[34m(self, thread)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Select the next speaker.\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(participants) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     agent_name = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._select_speaker(roles, participants, \u001b[38;5;28mself\u001b[39m._max_selector_attempts)\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     agent_name = participants[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_selector_group_chat.py:269\u001b[39m, in \u001b[36mSelectorGroupChatManager._select_speaker\u001b[39m\u001b[34m(self, roles, participants, max_attempts)\u001b[39m\n\u001b[32m    267\u001b[39m     response = chunk\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_client.create(messages=select_speaker_messages)\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.content, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    271\u001b[39m select_speaker_messages.append(AssistantMessage(content=response.content, source=\u001b[33m\"\u001b[39m\u001b[33mselector\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:704\u001b[39m, in \u001b[36mBaseOpenAIChatCompletionClient.create\u001b[39m\u001b[34m(self, messages, tools, tool_choice, json_output, extra_create_args, cancellation_token)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    703\u001b[39m     cancellation_token.link_future(future)\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m create_params.response_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     result = cast(ParsedChatCompletion[Any], result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2678\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   2632\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   2633\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2675\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2676\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2677\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2678\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2679\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2680\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2681\u001b[39m             {\n\u001b[32m   2682\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2683\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2684\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2685\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2686\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2687\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2688\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2689\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2690\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2691\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2692\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2693\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2694\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2695\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2696\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2697\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2698\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2699\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_retention\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_retention,\n\u001b[32m   2700\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2701\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2702\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2703\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2704\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2705\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2706\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2707\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2708\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2709\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2710\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2711\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2712\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2713\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2714\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2715\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2716\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2717\u001b[39m             },\n\u001b[32m   2718\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2719\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2720\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2721\u001b[39m         ),\n\u001b[32m   2722\u001b[39m         options=make_request_options(\n\u001b[32m   2723\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2724\u001b[39m         ),\n\u001b[32m   2725\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2726\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2727\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2728\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/openai/_base_client.py:1797\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1784\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1785\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1792\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1793\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1794\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1795\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1796\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1797\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Python-Autogen/.venv/lib/python3.12/site-packages/openai/_base_client.py:1597\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1594\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1596\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1597\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1599\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - [{'error': {'code': 400, 'message': 'API key expired. Please renew the API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key expired. Please renew the API key.'}]}}]"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "\n",
    "TASK = \"Plan a 4-day trip to Mexico City. Provide suggestions for activities, places to visit, and language tips.\"\n",
    "\n",
    "if model_client:\n",
    "    print(\">>> MODE 1: PARALLEL execution running...\")\n",
    "    await run_parallel_team(\n",
    "        task=TASK, \n",
    "        specialist_agents=[planner_agent, local_agent, language_agent], \n",
    "        summary_agent=travel_summary_agent_parallel,\n",
    "        filename=\"output_mode_a_parallel.txt\"\n",
    "    )\n",
    "    print(\">>> MODE 1: DONE. Output saved to output_mode_a_parallel.txt\\n\")\n",
    "\n",
    "    print(\">>> MODE 2: ROUND ROBIN execution running...\")\n",
    "    # Note: Using interactive summary agent that knows to TERMINATE\n",
    "    await run_round_robin_team(\n",
    "        task=TASK,\n",
    "        participants=[planner_agent, local_agent, language_agent, travel_summary_agent_interactive],\n",
    "        filename=\"output_mode_b_round_robin.txt\"\n",
    "    )\n",
    "    print(\">>> MODE 2: DONE. Output saved to output_mode_b_round_robin.txt\\n\")\n",
    "\n",
    "    print(\">>> MODE 3: DYNAMIC ROUTER execution running...\")\n",
    "    await run_dynamic_router_team(\n",
    "        task=TASK,\n",
    "        participants=[planner_agent, local_agent, language_agent, travel_summary_agent_interactive],\n",
    "        model_client=model_client,\n",
    "        filename=\"output_mode_c_dynamic.txt\"\n",
    "    )\n",
    "    print(\">>> MODE 3: DONE. Output saved to output_mode_c_dynamic.txt\\n\")\n",
    "\n",
    "else:\n",
    "    print(\"Model client invalid. Check API Key.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
